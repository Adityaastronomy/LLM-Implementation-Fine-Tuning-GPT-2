{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 2159, 220]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding( \"gpt2\" )\n",
    "text = ( \"Hello World \")\n",
    "integers = tokenizer.encode( text )\n",
    "print ( integers ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Layer Normalisation and Feed Forward Neural Network\n",
    "class LayerNorm( nn.Module ):\n",
    "    def __init__( self , emb_dim ):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter( torch.ones( emb_dim ))\n",
    "        self.shift = nn.Parameter( torch.zeros( emb_dim ))\n",
    "\n",
    "\n",
    "    def forward( self , x ):\n",
    "        mean = x.mean( dim = -1 , keepdim = True )\n",
    "        var = x.var( dim = -1 , keepdim = True , unbiased = True )\n",
    "        norm_x = ( x - mean ) / torch.sqrt( var + self.eps )\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "\n",
    "class GELU( nn.Module ):\n",
    "    def __init__( self  ):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward( self , x ):\n",
    "        return 0.5 * x * ( 1 + torch.tanh( \n",
    "            torch.sqrt( torch.tensor( 2.0 / torch.pi )) * \n",
    "            ( x + 0.044715 * torch.pow( x , 3 )) \n",
    "        ))\n",
    "\n",
    "class FeedForward( nn.Module ):\n",
    "    def __init__( self , cfg ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear( cfg[\"emb_dim\" ] , 4 * cfg[\"emb_dim\" ] ),\n",
    "            GELU(),\n",
    "            nn.Linear( 4 * cfg[ \"emb_dim\"] , cfg[ \"emb_dim\" ]),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward( self , x ):\n",
    "        return self.layers( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MutiHead Attention Mech\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transformer Class\n",
    "class TransformerBlock( nn.Module ):\n",
    "    def __init__( self , cfg ):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention( \n",
    "            d_in = cfg[ \"emb_dim\"],\n",
    "            d_out = cfg[ \"emb_dim\"],\n",
    "            context_length = cfg[ \"context_length\"],\n",
    "            num_heads = cfg[ \"n_heads\"],\n",
    "            dropout = cfg[ \"drop_rate\"],\n",
    "            qkv_bias = cfg[ \"qkv_bias\"],\n",
    "\n",
    "        )\n",
    "        self.ff = FeedForward( cfg )\n",
    "        self.norm1 = LayerNorm( cfg[ \"emb_dim\"])\n",
    "        self.norm2 = LayerNorm( cfg[ \"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout( cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward( self , x ):\n",
    "        shortcut = x\n",
    "        x = self.norm1( x )\n",
    "        x = self.att( x )\n",
    "        x = self.drop_shortcut( x )\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2( x )\n",
    "        x = self.ff( x )\n",
    "        x = self.drop_shortcut( x )\n",
    "        x = x + shortcut\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now to Code the GPT Architecture\n",
    "class GPTModel( nn.Module ):\n",
    "    def __init__(self , cfg ):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding( cfg[\"vocab_size\"] , cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding( cfg[\"context_length\" ] , cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout( cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential( \n",
    "            *[TransformerBlock( cfg ) for _ in range(cfg[ \"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm( cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"] , cfg[ \"vocab_size\"], bias=  False\n",
    "        )\n",
    "\n",
    "    def forward( self , in_idx ):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb( in_idx )\n",
    "        pos_embeds = self.pos_emb( torch.arange( seq_len , device = in_idx.device ))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb( x )\n",
    "        x = self.trf_blocks( x )\n",
    "        x = self.final_norm( x )\n",
    "        logits = self.out_head( x )\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids( text , tokenizer ):\n",
    "    encoded = tokenizer.encode( text , allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor( encoded ).unsqueeze( 0 )\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text( token_ids , tokenizer ):\n",
    "    flat = token_ids.squeeze( 0 )\n",
    "    return tokenizer.decode( flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained weights from Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/adityaastronomy/Library/Python/3.12/lib/python/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/adityaastronomy/Library/Python/3.12/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/adityaastronomy/Library/Python/3.12/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "zsh:1: 2.15.0 not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Loading Pretrained weights from Open AI\n",
    "%pip install tensorflow\n",
    "%pip install tqdm\n",
    "%pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version  2.18.0\n",
      "tqdm Version  4.67.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "print( \"Tensorflow version \", tf.__version__ )\n",
    "print( \"tqdm Version \", tqdm.__version__ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign( left , right ):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError( f\"Shape mismatched. Left: { left.shape } , Right : { right.shape }\")\n",
    "    \n",
    "    return torch.nn.Parameter( torch.tensor( right ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now link the GPT Model class with the downloaded weights\n",
    "# import numpy as np\n",
    "\n",
    "# def load_weight_into_gpt( gpt , params ):\n",
    "#     gpt.pos_emb.weight = assign( gpt.pos_emb.weight , params[ 'wpe'])\n",
    "#     gpt.tok_emb.weight = assign( gpt.tok_emb.weight , params[ 'wte'])\n",
    "\n",
    "#     for b in range( len( params[ 'blocks'])):\n",
    "#         # weight part \n",
    "#         q_w, k_w , v_w = np.split(\n",
    "#             (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"] , 3 , axis = -1 )\n",
    "#         gpt.trf_blocks[b].att.W_query.weight = assign( gpt.trf_blocks[b].att.W_query.weight , q_w.T )\n",
    "#         gpt.trf_blocks[b].att.W_key.weight = assign(  gpt.trf_blocks[b].att.W_key.weight , k_w.T)\n",
    "#         gpt.trf_blocks[b].att.W_value.weight = assign( gpt.trf_blocks[b].att.W_value.weight , v_w.T )\n",
    "\n",
    "#         # bias part \n",
    "#         q_b , k_b , v_b = np.split(\n",
    "#             (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"] , 3 , axis = -1\n",
    "#         )\n",
    "#         gpt.trf_blocks[b].att.W_query.bias = assign( gpt.trf_blocks[b].att.W_query.bias , q_b )\n",
    "#         gpt.trf_blocks[b].att.W_key.bias = assign(  gpt.trf_blocks[b].att.W_key.bias , k_b )\n",
    "#         gpt.trf_blocks[b].att.W_value.bias = assign( gpt.trf_blocks[b].att.W_value.bias , v_b )\n",
    "\n",
    "#         # output project weight \n",
    "#         gpt.trf_blocks[b].att.out_proj.weight = assign( gpt.trf_blocks[b].att.out_proj.weight , params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T )\n",
    "#         gpt.trf_blocks[b].att.out_proj.bias = assign( gpt.trf_blocks[b].att.out_proj.bias , params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"] )\n",
    "\n",
    "#         # Feed Forward NN -> Fully connected layer\n",
    "#         gpt.trf_blocks[b].ff.layers[0].weight = assign( gpt.trf_blocks[b].ff.layers[0].weight , params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T )\n",
    "#         gpt.trf_blocks[b].ff.layers[0].bias = assign( gpt.trf_blocks[b].ff.layers[0].bias , params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"] )\n",
    "#         # Projection layer \n",
    "#         gpt.trf_blocks[b].ff.layers[2].weight = assign( gpt.trf_blocks[b].ff.layers[2].weight , params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T )\n",
    "#         gpt.trf_blocks[b].ff.layers[2].bias = assign( gpt.trf_blocks[b].ff.layers[2].bias , params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"] )\n",
    "\n",
    "#         # layer normalisation 1 and 2\n",
    "#         gpt.trf_blocks[b].norm1.scale = assign( gpt.trf_blocks[b].norm1.scale , params[\"blocks\"][b][\"ln_1\"][\"g\"] )\n",
    "#         gpt.trf_blocks[b].norm1.shift = assign( gpt.trf_blocks[b].norm1.shift , params[\"blocks\"][b][\"ln_1\"][\"b\"] )\n",
    "\n",
    "#         gpt.trf_blocks[b].norm2.scale = assign( gpt.trf_blocks[b].norm2.scale , params[\"blocks\"][b][\"ln_1\"][\"g\"] )\n",
    "#         gpt.trf_blocks[b].norm2.shift = assign( gpt.trf_blocks[b].norm2.shift , params[\"blocks\"][b][\"ln_1\"][\"b\"] )\n",
    "\n",
    "#     # Final parameters left affter transformer block\n",
    "#     gpt.final_norm.scale = assign( gpt.final_norm.scale , params[\"g\"] )\n",
    "#     gpt.final_norm.shift = assign( gpt.final_norm.shift , params[\"b\"] )\n",
    "#     gpt.out_head.weight = assign( gpt.out_head.weight , params[\"wte\"])\n",
    "    \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning for Classification - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adityaastronomy/Desktop/LLM/sms_spam_collection/SMSSpamCollection.tsv already exist, skipping the Download Part \n"
     ]
    }
   ],
   "source": [
    "## Fine Tuning for Classification - Classification\n",
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/dataset/228/sms+spam+collection.zip\"\n",
    "zip_path = \"/Users/adityaastronomy/Desktop/LLM/sms_spam_collection.zip\"\n",
    "extracted_path = \"/Users/adityaastronomy/Desktop/LLM/sms_spam_collection\"\n",
    "data_file_path = Path( extracted_path ) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data( url , zip_path , extracted_path , data_file_path ):\n",
    "    if data_file_path.exists():\n",
    "        print( f\"{ data_file_path } already exist, skipping the Download Part \")\n",
    "        return \n",
    "    \n",
    "    # create an unverifed SSL Content\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Download the file \n",
    "    with urllib.request.urlopen( url , context = ssl_context ) as response :\n",
    "        with open( zip_path , \"wb\" ) as out_file : \n",
    "            out_file.write( response.read())\n",
    "\n",
    "    #unzipping the file\n",
    "    with zipfile.ZipFile( zip_path , \"r\" ) as zip_ref:\n",
    "        zip_ref.extractall( extracted_path )\n",
    "\n",
    "    #Add .tsv file extension \n",
    "    original_file_path = Path( extracted_path ) / \"SMSSpamCollection\"\n",
    "    os.rename( original_file_path , data_file_path )\n",
    "    print( f\"file downloaded and saved as { data_file_path }\")\n",
    "\n",
    "\n",
    "download_and_unzip_spam_data( url , zip_path , extracted_path , data_file_path )\n",
    "\n",
    "## Download this Mannually from the site \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Labels                                               Text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham               Will ü b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv( data_file_path , sep = \"\\t\" , header = None , names = [\"Labels\" , \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print( df[\"Labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n",
      "     Labels                                               Text\n",
      "4307    ham  Awww dat is sweet! We can think of something t...\n",
      "4138    ham                             Just got to  &lt;#&gt;\n",
      "4831    ham  The word \"Checkmate\" in chess comes from the P...\n",
      "4461    ham  This is wishing you a great day. Moji told me ...\n",
      "5440    ham      Thank you. do you generally date the brothas?\n",
      "...     ...                                                ...\n",
      "5537   spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540   spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547   spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566   spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[1494 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# This is imbalance data set , now lets make it a balanced data set \n",
    "# so we randomly take 747 data ebtries from spam and no spam part \n",
    "\n",
    "def create_balanced_dataset( df ):\n",
    "\n",
    "    num_spam = df[df[\"Labels\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # Randomly select \n",
    "    ham_subset = df[ df[\"Labels\"] == \"ham\"].sample( num_spam , random_state = 123 )\n",
    "\n",
    "    balanced_df = pd.concat( [ ham_subset , df[df[\"Labels\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df \n",
    "\n",
    "balanced_df = create_balanced_dataset( df )\n",
    "print( balanced_df[\"Labels\"].value_counts())\n",
    "print( balanced_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Labels\"] = balanced_df[\"Labels\"].map( { \"ham\" : 0 , \"spam\" : 1 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Labels                                               Text\n",
      "4307       0  Awww dat is sweet! We can think of something t...\n",
      "4138       0                             Just got to  &lt;#&gt;\n",
      "4831       0  The word \"Checkmate\" in chess comes from the P...\n",
      "4461       0  This is wishing you a great day. Moji told me ...\n",
      "5440       0      Thank you. do you generally date the brothas?\n",
      "...      ...                                                ...\n",
      "5537       1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540       1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547       1  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566       1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567       1  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[1494 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print( balanced_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitin the data set as 70 % - training , 10 % - validation and 20 % -test \n",
    "def random_split( df , train_frac , validation_frac ):\n",
    "\n",
    "    df = df.sample( frac= 1 , random_state= 123 ).reset_index( drop = True )\n",
    "\n",
    "    train_end = int( len(df) * train_frac )\n",
    "    validation_end = train_end + int( len( df ) * validation_frac )\n",
    "\n",
    "    # Diving the df\n",
    "    train_df = df[ : train_end ]\n",
    "    validation_df = df[ train_end : validation_end ]\n",
    "    test_df = df[ validation_end : ]\n",
    "\n",
    "    return train_df , validation_df , test_df\n",
    "\n",
    "train_df , validation_df , test_df = random_split( balanced_df , 0.7 , 0.1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print( len( train_df ))\n",
    "print( len( validation_df ))\n",
    "print( len( test_df ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the dataset \n",
    "train_df.to_csv( \"train.csv\" , index = None )\n",
    "validation_df.to_csv( \"validation.csv\" , index = None )\n",
    "test_df.to_csv( \"test.csv\" , index = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data Loaders\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset( Dataset ):\n",
    "    def __init__( self , csv_file , tokenizer , max_length = None , pad_token_id = 50256 ):\n",
    "        self.data = pd.read_csv( csv_file )\n",
    "\n",
    "        # Pre tokenize text \n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode( text ) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            # Truncate the seq \n",
    "            self.encoded_texts = [\n",
    "                encoded_text[ : self.max_length ]\n",
    "                for encoded_text in self.encoded_texts \n",
    "            ]\n",
    "\n",
    "        # Padding\n",
    "        self.encoded_texts = [ encoded_text + [ pad_token_id ] * ( self.max_length - len( encoded_text ))\n",
    "                              for encoded_text in self.encoded_texts \n",
    "                              ]\n",
    "        \n",
    "    def __getitem__( self , index ):\n",
    "        encoded = self.encoded_texts[ index ]\n",
    "        label = self.data.iloc[ index ][ 'Labels']\n",
    "        return (\n",
    "            torch.tensor( encoded , dtype = torch.long ),\n",
    "            torch.tensor( label , dtype = torch.long )\n",
    "        )\n",
    "    \n",
    "    def __len__( self ):\n",
    "        return len( self.data )\n",
    "    \n",
    "    def _longest_encoded_length( self ):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts : \n",
    "            encoded_length = len( encoded_text )\n",
    "            if( encoded_length > max_length ):\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file= \"train.csv\",\n",
    "    max_length= None ,\n",
    "    tokenizer= tokenizer\n",
    ")\n",
    "\n",
    "print( train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file = \"validation.csv\",\n",
    "    max_length= train_dataset.max_length,\n",
    "    tokenizer= tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file= \"test.csv\",\n",
    "    max_length= train_dataset.max_length,\n",
    "    tokenizer= tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data set will be served as a input to the dataloader \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_wokers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed( 123 )\n",
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset , \n",
    "    batch_size= batch_size , \n",
    "    num_workers= num_wokers,\n",
    "    drop_last= True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset= val_dataset ,\n",
    "    batch_size= batch_size ,\n",
    "    num_workers= num_wokers,\n",
    "    drop_last= False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset= test_dataset ,\n",
    "    batch_size= batch_size ,\n",
    "    num_workers= num_wokers,\n",
    "    drop_last= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader : \n",
      "Input Batch Dimension : torch.Size([8, 120])\n",
      "Target Batch Dimension : torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader : \")\n",
    "\n",
    "for input_batch , target_batch in train_loader :\n",
    "    pass\n",
    "\n",
    "print( \"Input Batch Dimension :\" , input_batch.shape )\n",
    "print( \"Target Batch Dimension :\" , target_batch.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches \n",
      "19 validation batches \n",
      "38 test batches \n"
     ]
    }
   ],
   "source": [
    "print( f\"{len (train_loader )} training batches \")\n",
    "print( f\"{len(val_loader) } validation batches \")\n",
    "print( f\"{len(test_loader) } test batches \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the model with GPT 2 weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves \"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\" : 50257,\n",
    "    \"context_length\" : 1024,\n",
    "    \"drop_rate\" : 0.0,\n",
    "    \"qkv_bias\" : True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\" : { \"emb_dim\" : 768 , \"n_layers\" : 12 , \"n_heads\" : 12 },\n",
    "    \"gpt2-medium (355M)\" : { \"emb_dim\" : 1024 , \"n_layers\" : 24 , \"n_heads\" : 16 }, \n",
    "    \"gpt2-large (774M)\" : { \"emb_dim\" : 1280 , \"n_layers\" : 36 , \"n_heads\" : 20 }, \n",
    "    \"gpt2-xl (1558M)\" : { \"emb_dim\" : 1600 , \"n_layers\" : 48 , \"n_heads\" : 25 }, \n",
    "}\n",
    "\n",
    "BASE_CONFIG.update( model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Data Set length {train_dataset.max_length } exceeds the model's context length \"\n",
    "    f\"length {BASE_CONFIG[\"context_length\"]}. Reinitialise data set with \"\n",
    "    f\"`max_length ={ BASE_CONFIG[\"context_length\"] }`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n",
      "Setting :  {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys :  dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[ - 1 ].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings , params = download_and_load_gpt2( model_size= model_size , models_dir= \"gpt2\")\n",
    "print( \"Setting : \", settings)\n",
    "print( 'Parameter dictionary keys : ' , params.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the model with GPT 2 weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel( BASE_CONFIG )\n",
    "load_weights_into_gpt( model , params )\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids( text , tokenizer ):\n",
    "    encoded = tokenizer.encode( text , allowed_special = {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor( encoded ).unsqueeze( 0 )\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text( token_ids , tokenizer ):\n",
    "    flat = token_ids.squeeze( 0 )\n",
    "    return tokenizer.decode( flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_sample( model , idx , max_new_tokens , context_size ):\n",
    "    # idx is the ( batch , n_tokens ) array of the indices in the current context\n",
    "    for _ in range( max_new_tokens ):\n",
    "        idx_cond = idx[:, -context_size: ]\n",
    "        with torch.no_grad():\n",
    "            logits = model( idx_cond )\n",
    "\n",
    "        logits = logits[ :, -1, :]\n",
    "\n",
    "        probas = torch.softmax( logits , dim = -1 )\n",
    "    \n",
    "        idx_next = torch.argmax( probas , dim = -1 , keepdim = True )\n",
    "\n",
    "        idx = torch.cat((idx , idx_next ), dim = 1 )\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you  to the next step.\n",
      "The first step is to find the right\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Every effort moves you \"\n",
    "token_ids = generate_text_sample(\n",
    "    model = model ,\n",
    "    idx = text_to_token_ids( text1 , tokenizer ),\n",
    "    max_new_tokens= 15 , \n",
    "    context_size= BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print( token_ids_to_text( token_ids , tokenizer ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'Yes' or 'No'You are a winner you have been speciallyselected for receive $10000 cash or $2000 award. 'Spam' means spamming or sending unwanted or unwanted messages. 'Spam' means spamming or sending unwanted\n"
     ]
    }
   ],
   "source": [
    "# Lets check that our base model can classify the given mail as spam or no spam \n",
    "text2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'Yes' or 'No\"\n",
    "    \"'You are a winner you have been specially\"\n",
    "    \"selected for receive $10000 cash or $2000 award. '\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_sample(\n",
    "    model = model ,\n",
    "    idx = text_to_token_ids( text2 , tokenizer ),\n",
    "    max_new_tokens= 23 , \n",
    "    context_size= BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print( token_ids_to_text( token_ids , tokenizer ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model fail to give the correct output because it has only under gone pretraining not fine tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Output Layer is now changed from dimension - 768 * 50257 to 768 * 2 for predicting spam or no spam\n",
    "# Therfore we are fine tuing inky the final transformer block\n",
    "\n",
    "# finetune :\n",
    "    # - Final Output Layer\n",
    "    # - Final Transformer Block \n",
    "    # - Final Layer Normal Module \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a classification heas at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Original model architecture\n",
    "print( model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed( 123 )\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear( in_features= BASE_CONFIG[\"emb_dim\"] , out_features= num_classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[ -1 ].parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs : tensor([[5211,  345,  423,  640]])\n",
      "Inputs Dimesions : torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode( \"Do you have time\")\n",
    "inputs = torch.tensor( inputs ).unsqueeze( 0 )\n",
    "print(\"Inputs :\" , inputs )\n",
    "print(\"Inputs Dimesions :\" , inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: \n",
      " tensor([[[-1.5883,  0.9920],\n",
      "         [-3.7208,  7.4510],\n",
      "         [-2.2642,  6.6005],\n",
      "         [-3.5965,  3.9889]]])\n",
      "Output Dimension: \n",
      "  torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model( inputs )\n",
    "\n",
    "print(\"Outputs: \\n\" , outputs )\n",
    "print(\"Output Dimension: \\n \", outputs.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Token Output : tensor([[-3.5965,  3.9889]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last Token Output :\" , outputs[ : ,-1, : ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calclulating the Classification Loss and Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0753e-04, 9.9949e-01]])\n",
      "Class Label : 1\n"
     ]
    }
   ],
   "source": [
    "#  Apply softmax \n",
    "probas = torch.softmax( outputs[ :, -1 , :] , dim = -1 )\n",
    "print( probas )\n",
    "label = torch.argmax( probas )\n",
    "print(\"Class Label :\" , label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Label : 1\n"
     ]
    }
   ],
   "source": [
    "# or either we can just take the max value for outputs\n",
    "logits = outputs[ :, -1 , : ]\n",
    "label = torch.argmax( logits )\n",
    "print(\"Class Label :\" , label.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader( data_loader , model , device , num_batches = None ):\n",
    "    model.eval()\n",
    "    correct_predictions , num_examples = 0 , 0 \n",
    "    \n",
    "    if num_batches is None :\n",
    "        num_batches = len( data_loader )\n",
    "    else :\n",
    "        num_batches = min( num_batches , len( data_loader ))\n",
    "\n",
    "    for i , ( input_batch , target_batch ) in enumerate( data_loader ):\n",
    "        if i < num_batches:\n",
    "            input_batch , target_batch = input_batch.to( device ) , target_batch.to( device )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model( input_batch )[ :, -1 , :]\n",
    "            predicted_labels = torch.argmax( logits , dim = -1 )\n",
    "\n",
    "            num_examples += predicted_labels.shape[ 0 ]\n",
    "            correct_predictions += ( predicted_labels == target_batch ).sum().item()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return correct_predictions / num_examples \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 47.50%\n",
      "Validation Accuracy : 45.00%\n",
      "Test Accuracy : 48.75%\n"
     ]
    }
   ],
   "source": [
    "# This is just a random value run \n",
    "\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to( device )\n",
    "torch.manual_seed( 123 )\n",
    "train_accuracy = calc_accuracy_loader( train_loader , model , device , num_batches= 10 )\n",
    "val_accuracy = calc_accuracy_loader( val_loader , model , device , num_batches= 10 )\n",
    "test_accuracy = calc_accuracy_loader( test_loader , model , device , num_batches= 10 )\n",
    "\n",
    "\n",
    "print( f\"Training Accuracy : {train_accuracy * 100 :.2f}%\")\n",
    "print( f\"Validation Accuracy : {val_accuracy * 100 :.2f}%\")\n",
    "print( f\"Test Accuracy : {test_accuracy * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch( input_batch , target_batch , model , batch ):\n",
    "    input_batch , target_batch  = input_batch.to( device ) , target_batch.to( device )\n",
    "    logits = model( input_batch )[ :, -1 , :]\n",
    "    loss = torch.nn.functional.cross_entropy( logits , target_batch )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss calculation for multiple batches\n",
    "def calc_loss_loader( data_loader , model , device , num_batches = None ):\n",
    "    total_loss = 0 \n",
    "    if len( data_loader ) == 0 :\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    elif num_batches is None:\n",
    "        num_batches = len( data_loader )\n",
    "\n",
    "    else :\n",
    "        num_batches = min( num_batches, len( data_loader ))\n",
    "\n",
    "        \n",
    "    for i , ( input_batch , target_batch ) in enumerate( data_loader ):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch( input_batch , target_batch , model , device )\n",
    "            total_loss += loss\n",
    "        else : \n",
    "            break\n",
    "    \n",
    "\n",
    "    return total_loss/ num_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 3.070\n",
      "Validation Loss : 2.575\n",
      "Test Loss : 2.314\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader( train_loader , model , device , num_batches= 5 )\n",
    "    val_loss = calc_loss_loader( val_loader , model , device , num_batches= 5 )\n",
    "    test_loss = calc_loss_loader( test_loader , model , device , num_batches= 5 )\n",
    "\n",
    "print( f\"Training Loss : {train_loss:.3f}\")\n",
    "print( f\"Validation Loss : {val_loss:.3f}\")\n",
    "print( f\"Test Loss : {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning The Mode on Supervised DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Set the Model to training mode \n",
    "### Step 2 : Reset the loss Gradient from the previous batch \n",
    "### Step 3 : Calaculate the loss Gradient \n",
    "### Step 4 : Update Model weights using loss gradients\n",
    "### Step 5 : New track examples instead of tokens\n",
    "### Step 6 : Optinal Evaluation Step\n",
    "### Step 7 : Calaculate the accuracy after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple( model , train_loader , val_loader , optimizer , device , num_epochs , eval_freq , eval_iter ):\n",
    "\n",
    "    train_losses , val_losses , train_accs , val_accs = [] , [] , [] , []\n",
    "    examples_seen , global_step = 0 , -1 \n",
    "\n",
    "    for epoch in range(num_epochs) :\n",
    "        model.train() # set the model in training mode\n",
    "\n",
    "        for input_batch , target_batch in train_loader :\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch( input_batch , target_batch , model , device )\n",
    "            loss.backward() # calc loss gradient \n",
    "\n",
    "            optimizer.step()    #update the model weights using loss gradient \n",
    "            examples_seen += input_batch.shape[ 0 ]\n",
    "            global_step += 1\n",
    "\n",
    "            ## 130 batches : training , eval_freq = 50 --> after 50 batches are proceesed in each epoch , we print train loss and validation loss \n",
    "            #Optinal Step Evaluation\n",
    "            if global_step % eval_freq == 0 :\n",
    "                train_loss, val_loss = evaluate_model( \n",
    "                    model , train_loader , val_loader , device , eval_iter\n",
    "                )\n",
    "                train_losses.append( train_loss )\n",
    "                val_losses.append( val_loss )\n",
    "                print( f\"Ep { epoch + 1 } (Step {global_step:06d}) : \"\n",
    "                       f\"Train Loss { train_loss :.3f}, Validation Loss {val_loss :.3f}\")\n",
    "\n",
    "\n",
    "        # calculated the accuracy after each epoch \n",
    "\n",
    "        train_accuracy = calc_accuracy_loader( train_loader , model , device , num_batches= eval_iter )\n",
    "        val_accuracy = calc_accuracy_loader( val_loader , model , device , num_batches= eval_iter )\n",
    "        print( f\"Training Accuracy : { train_accuracy * 100 :.2f} %\" , end = \"\")\n",
    "        print( f\"Validation Accuracy : { val_accuracy * 100 :.2f} %\")\n",
    "        train_accs.append( train_accuracy )\n",
    "        val_accs.append( val_accuracy )\n",
    "\n",
    "    return train_losses , val_losses , train_accs , val_accs , examples_seen \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model( model , train_loader , val_loader , device , eval_iter ):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader( train_loader , model , device , num_batches= eval_iter )\n",
    "        val_loss = calc_loss_loader( val_loader , model , device , num_batches= eval_iter )\n",
    "    model.train()\n",
    "    return train_loss , val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000) : Train Loss 2.120, Validation Loss 1.786\n",
      "Ep 1 (Step 000050) : Train Loss 0.626, Validation Loss 0.640\n",
      "Ep 1 (Step 000100) : Train Loss 0.553, Validation Loss 0.585\n",
      "Training Accuracy : 67.50 %Validation Accuracy : 57.50 %\n",
      "Ep 2 (Step 000150) : Train Loss 0.522, Validation Loss 0.487\n",
      "Ep 2 (Step 000200) : Train Loss 0.433, Validation Loss 0.398\n",
      "Ep 2 (Step 000250) : Train Loss 0.396, Validation Loss 0.299\n",
      "Training Accuracy : 87.50 %Validation Accuracy : 95.00 %\n",
      "Ep 3 (Step 000300) : Train Loss 0.271, Validation Loss 0.137\n",
      "Ep 3 (Step 000350) : Train Loss 0.261, Validation Loss 0.082\n",
      "Training Accuracy : 92.50 %Validation Accuracy : 97.50 %\n",
      "Ep 4 (Step 000400) : Train Loss 0.197, Validation Loss 0.070\n",
      "Ep 4 (Step 000450) : Train Loss 0.172, Validation Loss 0.088\n",
      "Ep 4 (Step 000500) : Train Loss 0.156, Validation Loss 0.064\n",
      "Training Accuracy : 95.00 %Validation Accuracy : 97.50 %\n",
      "Ep 5 (Step 000550) : Train Loss 0.133, Validation Loss 0.072\n",
      "Ep 5 (Step 000600) : Train Loss 0.148, Validation Loss 0.041\n",
      "Training Accuracy : 95.00 %Validation Accuracy : 97.50 %\n",
      "Training completed in 10.49 minutes \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed( 123 )\n",
    "\n",
    "optimizer = torch.optim.AdamW( model.parameters() , lr = 5e-5 , weight_decay= 0.1 )\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses , val_losses , train_accs , val_accs , example_seen = train_classifier_simple( \n",
    "    model , train_loader , val_loader , optimizer , device , \n",
    "    num_epochs = num_epochs , eval_freq= 50 , eval_iter= 5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = ( end_time - start_time ) / 60 \n",
    "print( f\"Training completed in { execution_time_minutes :.2f} minutes \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values( epochs_seen , example_seen , train_values , val_values , label = \"loss\"):\n",
    "    fig , ax1 = plt.subplots( figsize=( 5 , 3 ))\n",
    "\n",
    "    # Plot the Training loss and Validation Loss\n",
    "    ax1.plot( epochs_seen , train_values , label = f\"Trainig {label}\")\n",
    "    ax1.plot( epochs_seen ,  val_values , linestyle = \"-.\" , label = f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot( example_seen , train_values , alpha = 0 )\n",
    "    ax2.set_xlabel(\"Example Seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig( f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace( 0 , num_epochs , len( train_losses ))\n",
    "example_seen_tensor = torch.linspace( 0 , example_seen , len( train_losses ) )\n",
    "\n",
    "\n",
    "plot_values( epochs_tensor , example_seen_tensor , train_losses , val_losses )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 97.60 %\n",
      "validation Accuracy : 98.66 %\n",
      "Test Accuracy : 96.00 %\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader( train_loader , model , device )\n",
    "val_accuracy = calc_accuracy_loader( val_loader , model , device )\n",
    "test_accuracy = calc_accuracy_loader( test_loader , model , device )\n",
    "\n",
    "print( f\"Training Accuracy : { train_accuracy * 100 :.2f} %\")\n",
    "print( f\"validation Accuracy : { val_accuracy * 100 :.2f} %\")\n",
    "print( f\"Test Accuracy : { test_accuracy * 100 :.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LLM as a Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review( text , model , tokenizer , device , max_length = None  , pad_token_id = 50256 ):\n",
    "    model.eval()\n",
    "\n",
    "    # prepare input to the model \n",
    "    input_ids = tokenizer.encode( text )\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    # Truncate the sequence if it is too long \n",
    "    input_ids = input_ids[ :min( max_length , supported_context_length )]\n",
    "\n",
    "    #pad the sequence to the longest sequence \n",
    "    input_ids += [ pad_token_id ] * ( max_length - len( input_ids ))\n",
    "\n",
    "    input_tensor = torch.tensor( input_ids , device= device ).unsqueeze( 0 )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model( input_tensor )[ :, -1 ,: ]\n",
    "    predicted_label = torch.argmax( logits , dim = -1 ).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print( classify_review(\n",
    "    text1 , model , tokenizer , device , max_length= train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(  classify_review(\n",
    "    text2 , model , tokenizer , device , max_length= train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save( model.state_dict() , \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/j8l4b0cj5zqdl0273gsv8jgh0000gn/T/ipykernel_51791/3826764412.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch. load(\"review_classifier.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch. load(\"review_classifier.pth\")\n",
    "model. load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
